{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c995c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-1.22.2-cp310-cp310-win_amd64.whl (14.7 MB)\n",
      "     --------------------------------------- 14.7/14.7 MB 13.1 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.22.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bdeb71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.1-cp310-cp310-win_amd64.whl (10.6 MB)\n",
      "     ---------------------------------------- 10.6/10.6 MB 9.1 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\n",
      "     ------------------------------------- 503.5/503.5 KB 10.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\sashi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\sashi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.22.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sashi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.4.1 pytz-2021.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "911ea527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "     ---------------------------------------- 63.1/63.1 KB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sashi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
      "     -------------------------------------- 138.7/138.7 KB 8.0 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 61.2/61.2 KB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, requests\n",
      "Successfully installed charset-normalizer-2.0.12 idna-3.3 requests-2.27.1 urllib3-1.26.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14872db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 97.4/97.4 KB 2.8 MB/s eta 0:00:00\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.10.0 soupsieve-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dc57647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytime\n",
      "  Downloading pytime-0.2.2-py3-none-any.whl (9.2 kB)\n",
      "Installing collected packages: pytime\n",
      "Successfully installed pytime-0.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e2824127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.0.9-py2.py3-none-any.whl (242 kB)\n",
      "     ------------------------------------ 242.2/242.2 KB 927.7 kB/s eta 0:00:00\n",
      "Collecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef25710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import statistics as st\n",
    "import time\n",
    "from operator import itemgetter\n",
    "import datetime\n",
    "import os\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69741f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_1 = {\n",
    "    'フェブラリーS': 'https://db.sp.netkeiba.com/?pid=race_list&word=%A5%D5%A5%A7%A5%D6%A5%E9%A5%EA%A1%BC&track%5B%5D=2&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    '高松宮記念': 'https://db.sp.netkeiba.com/?pid=race_list&word=%B9%E2%BE%BE%B5%DC&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    '大阪杯': 'https://db.sp.netkeiba.com/?pid=race_list&word=%C2%E7%BA%E5%C7%D5&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    '桜花賞': 'https://db.sp.netkeiba.com/?pid=race_list&word=%BA%F9%B2%D6%BE%DE&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    '皐月賞': 'https://db.sp.netkeiba.com/?pid=race_list&word=%BB%A9%B7%EE%BE%DE&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    '天皇賞春': 'https://db.sp.netkeiba.com/?pid=race_list&word=%C5%B7%B9%C4%BE%DE%28%BD%D5%29&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    'NHKマイルC': 'https://db.sp.netkeiba.com/?pid=race_list&word=NHK&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    'ヴィクトリアマイル': 'https://db.sp.netkeiba.com/?pid=race_list&word=%A5%F4%A5%A3%A5%AF%A5%C8%A5%EA%A5%A2%A5%DE%A5%A4%A5%EB&start_year=none&start_mon=none&end_year=none&end_mon=none&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    'オークス': 'https://db.sp.netkeiba.com/?pid=race_list&word=%A5%AA%A1%BC%A5%AF%A5%B9&start_year=none&start_mon=none&end_year=none&end_mon=none&jyo%5B%5D=05&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=',\n",
    "    '日本ダービー': 'https://db.sp.netkeiba.com/?pid=race_list&word=%A5%C0%A1%BC%A5%D3%A1%BC&start_year=none&start_mon=none&end_year=none&end_mon=none&jyo%5B%5D=05&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    '安田記念': 'https://db.sp.netkeiba.com/?pid=race_list&word=%B0%C2%C5%C4%B5%AD%C7%B0&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    '宝塚記念': 'https://db.sp.netkeiba.com/?pid=race_list&word=%CA%F5%C4%CD%B5%AD%C7%B0&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    'スプリンターズS': 'https://db.sp.netkeiba.com/?pid=race_list&word=%A5%B9%A5%D7%A5%EA%A5%F3%A5%BF%A1%BC%A5%BA&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    '秋華賞': 'https://db.sp.netkeiba.com/?pid=race_list&word=%BA%F9%B2%D6%BE%DE&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    '天皇賞秋': 'https://db.sp.netkeiba.com/?pid=race_list&word=%C5%B7%B9%C4%BE%DE%28%BD%A9%29&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=', \n",
    "    'エリザベス': 'https://db.sp.netkeiba.com/?pid=race_list&word=%A5%A8%A5%EA%A5%B6%A5%D9%A5%B9%BD%F7%B2%A6&track%5B%5D=1&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=',\n",
    "    'マイルCS': 'https://db.sp.netkeiba.com/?pid=race_list&word=%A5%DE%A5%A4%A5%EBCS&track%5B%5D=1&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=',\n",
    "    'ジャパンC': 'https://db.sp.netkeiba.com/?pid=race_list&word=%A5%B8%A5%E3%A5%D1%A5%F3&track%5B%5D=1&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=',\n",
    "    'チャンピオンズC': 'https://db.sp.netkeiba.com/?pid=race_list&word=%A5%C1%A5%E3%A5%F3%A5%D4%A5%AA%A5%F3%A5%BAC&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=',\n",
    "    '阪神JF': 'https://db.sp.netkeiba.com/?pid=race_list&word=%BA%E5%BF%C0JF&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=',\n",
    "    '朝日杯': 'https://db.sp.netkeiba.com/?pid=race_list&word=%C4%AB%C6%FC%C7%D5&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit=',\n",
    "    '有馬記念': 'https://db.sp.netkeiba.com/?pid=race_list&word=%CD%AD%C7%CF%B5%AD%C7%B0&start_year=none&start_mon=none&end_year=none&end_mon=none&kyori_min=&kyori_max=&sort=date&submit=&page=1',\n",
    "    'ホープフルS': 'https://db.sp.netkeiba.com/?pid=race_list&word=%A5%DB%A1%BC%A5%D7&start_year=none&start_mon=none&end_year=none&end_mon=none&grade%5B%5D=1&kyori_min=&kyori_max=&sort=date&submit='\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc498ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g1\n",
      "レース名を入力：安田記念\n"
     ]
    }
   ],
   "source": [
    "#2ページ分のURLを取得\n",
    "if input() == 'g1':\n",
    "    page_url = G_1[input('レース名を入力：')]\n",
    "else:\n",
    "    page_url = input('スマホ版ネット競馬DBのURLを入力：')\n",
    "count = 0\n",
    "page_url_list = []\n",
    "for i in range(2):\n",
    "    if count != 0:\n",
    "        page_url = page_url.replace('&page=1','')+'&page=2'\n",
    "    page_url_list.append(page_url)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5139eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ページに記載されている1986年までのレースURLを取得\n",
    "count = 0\n",
    "race_url_list = []\n",
    "for i in page_url_list:\n",
    "    res = requests.get(i)\n",
    "    res.encoding = res.apparent_encoding # 呪文\n",
    "    time.sleep(1)\n",
    "    soup = BeautifulSoup(res.content,features='html.parser')\n",
    "    div = soup.find('div',attrs={'class':'Search_Result'})\n",
    "    try: \n",
    "        a = div.find_all('a')\n",
    "        race_name = div.find('span',attrs={'class':'LimitsWidth'}).text\n",
    "        count_2 = 0\n",
    "        if count == 0:\n",
    "            for i,k in enumerate(a):\n",
    "                if 'movie' not in a[i].get('href') and 'https' in a[i].get('href'):\n",
    "                    race_url_list.append(a[i].get('href'))\n",
    "                    count_2 += 1\n",
    "            count += 1\n",
    "        elif count != 0:\n",
    "            for i,k in enumerate(a):\n",
    "                if 'movie' not in a[i].get('href') and 'https' in a[i].get('href'):\n",
    "                    race_url_list.append(a[i].get('href'))\n",
    "                    count_2 += 1\n",
    "                    if '1986' in a[i].get('href'):\n",
    "                        break\n",
    "    except AttributeError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51eeb150",
   "metadata": {},
   "outputs": [],
   "source": [
    "class keiba():\n",
    "    def divident(list_,times):\n",
    "        #レースの配当を取得\n",
    "        year = []\n",
    "        tansyo = []\n",
    "        wakuren = []\n",
    "        umaren = []\n",
    "        umatan = []\n",
    "        sanpuku = []\n",
    "        santan = []\n",
    "\n",
    "        for count,i in enumerate(list_):\n",
    "            res = requests.get(i)\n",
    "            time.sleep(1)\n",
    "            res.encoding = res.apparent_encoding # 呪文\n",
    "            soup = BeautifulSoup(res.content,features='html.parser',from_encoding='utf-8')\n",
    "            if count == times:\n",
    "                    break\n",
    "            for count_2,j in enumerate(soup.find('div',attrs = {'class':'Result_Pay_Back'}).find_all('tbody')):\n",
    "                for l in j.find_all('td',attrs={'class':'Payout'}):\n",
    "                    if count_2 == 0:\n",
    "                        tansyo.append(int(re.sub('\\D+','',l.text)))\n",
    "                        year.append(int(soup.find('span',attrs={'class':'Race_Date'}).text.split('/')[0].replace(u'\\n','')))\n",
    "                    elif count_2 == 2:\n",
    "                        wakuren.append(int(re.sub('\\D+','',l.text)))\n",
    "                    elif count_2 == 3:\n",
    "                        umaren.append(int(re.sub('\\D+','',l.text)))\n",
    "                    elif count_2 == 5:\n",
    "                        umatan.append(int(re.sub('\\D+','',l.text)))\n",
    "                    elif count_2 == 6:\n",
    "                        sanpuku.append(int(re.sub('\\D+','',l.text)))\n",
    "                    elif count_2 == 7:\n",
    "                        santan.append(int(re.sub('\\D+','',l.text)))\n",
    "        data_name = ['平均値','中央値','最大値','最小値']\n",
    "        tansyo_data = []\n",
    "        wakuren_data = []\n",
    "        umaren_data = []\n",
    "        umatan_data = []\n",
    "        sanpuku_data = []\n",
    "        santan_data = []\n",
    "\n",
    "        tansyo_data.extend([int(st.mean(tansyo)),int(st.median(tansyo)),max(tansyo),min(tansyo)])\n",
    "        wakuren_data.extend([int(st.mean(wakuren)),int(st.median(wakuren)),max(wakuren),min(wakuren)])\n",
    "        umaren_data.extend([int(st.mean(umaren)),int(st.median(umaren)),max(umaren),min(umaren)])\n",
    "        umatan_data.extend([int(st.mean(umatan)),int(st.median(umatan)),max(umatan),min(umatan)])\n",
    "        sanpuku_data.extend([int(st.mean(sanpuku)),int(st.median(sanpuku)),max(sanpuku),min(sanpuku)])\n",
    "        santan_data.extend([int(st.mean(santan)),int(st.median(santan)),max(santan),min(santan)])\n",
    "        \n",
    "        df_divident = pd.DataFrame({'':data_name,'単勝':tansyo_data,'枠連':wakuren_data,'馬連':umaren_data,'馬単':umatan_data,'三連複':sanpuku_data,'三連単':santan_data})\n",
    "\n",
    "        return df_divident\n",
    "    \n",
    "    def result(list_,times):\n",
    "        #レースの結果を取得\n",
    "        #重複あり\n",
    "        year = []\n",
    "        baba = []\n",
    "        rank = []\n",
    "        waku = []\n",
    "        num = []\n",
    "        horse_url_list = []\n",
    "        horse_name = []\n",
    "        sex = []\n",
    "        age = []\n",
    "        tuka = []\n",
    "        one = []\n",
    "        two = []\n",
    "        three = []\n",
    "        four = []\n",
    "        hakuryo = []\n",
    "        jockey = []\n",
    "        odds = []\n",
    "        pop = []\n",
    "        weight = []\n",
    "        round_weight = []\n",
    "        weight_2 = []\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for count,i in enumerate(race_url_list):\n",
    "            res = requests.get(i)\n",
    "            time.sleep(1)\n",
    "            soup = BeautifulSoup(res.content,features='html.parser')\n",
    "            table = soup.find('table',attrs={'class':'table_slide_body ResultsByRaceDetail'})\n",
    "            x = 0\n",
    "            if count == times:\n",
    "                break\n",
    "            for j,k in enumerate(table.find_all('tr')):\n",
    "                if j > 0:\n",
    "                    for m,n in enumerate(k.find_all('td')):\n",
    "                        if m == 0:\n",
    "                            try:\n",
    "                                rank.append(int(n.text))\n",
    "                            #出走を取り消した場合\n",
    "                            except ValueError:\n",
    "                                break\n",
    "                        elif m == 1:\n",
    "                            if x == 0:\n",
    "                                year.append(int(soup.find('span',attrs={'class':'Race_Date'}).text.split('/')[0].replace(u'\\n','')))\n",
    "                                x += 1\n",
    "                            else:\n",
    "                                year.append('')\n",
    "                            baba.append(soup.find('div',attrs={'class':'RaceData'}).find_all('span')[4].text)\n",
    "                            waku.append(int(n.text))\n",
    "\n",
    "                        elif m == 2:\n",
    "                            num.append(int(n.text))\n",
    "\n",
    "                        elif m == 3:\n",
    "                            horse_url_list.append(n.find('a').get('href'))\n",
    "\n",
    "                            horse_name.append(n.text) \n",
    "\n",
    "\n",
    "                        elif m == 4:\n",
    "                            for count__ in range(2):\n",
    "                                if count__ == 0:\n",
    "                                    sex.append(re.sub('\\d+','',n.text))\n",
    "                                elif count__ != 0:\n",
    "                                    age.append(int(re.sub('\\D+','',n.text)))\n",
    "\n",
    "                        elif m == 5:\n",
    "                            hakuryo.append(int(n.text))\n",
    "\n",
    "                        elif m == 6:\n",
    "                            if n.text == 'Ｍデムー':\n",
    "                                jockey.append('Ｍ．デム')\n",
    "                            elif n.text == 'デムーロ':\n",
    "                                jockey.append('Ｃ．デム')\n",
    "                            elif n.text == 'Ｃ．ルメ' or n.text == 'Ｃルメー':\n",
    "                                jockey.appned('ルメール')\n",
    "                            else:\n",
    "                                jockey.append(n.text)\n",
    "\n",
    "                        elif m == 10:\n",
    "                            tuka.append(n.text)\n",
    "                            tmp = n.text.split('-')\n",
    "                            for count_10,corner in enumerate(tmp):\n",
    "                                if count_10 == 0:\n",
    "                                    one.append(int(corner))\n",
    "                                elif count_10 == 1:\n",
    "                                    two.append(int(corner))\n",
    "                                elif count_10 == 2:\n",
    "                                    three.append(int(corner))\n",
    "                                elif count_10 == 3:\n",
    "                                    four.append(int(corner))\n",
    "                            \n",
    "                        elif m == 12:\n",
    "                            try:\n",
    "                                odds.append(float(n.text))\n",
    "                            except ValueError:\n",
    "                                odds.append('')\n",
    "                        elif m == 13:\n",
    "                            pop.append(int(n.text))\n",
    "\n",
    "                        elif m == 14:\n",
    "                            tmp = n.text.split('(')\n",
    "                            for i in range(len(tmp)):\n",
    "                                if i == 0:\n",
    "                                    weight.append(int(tmp[i]))\n",
    "                                    excess = int(str(tmp[i])[-1])\n",
    "                                    round_num = int(tmp[i])-excess\n",
    "                                    round_weight.append(round_num)\n",
    "\n",
    "\n",
    "                                else:\n",
    "                                    weight_2.append(int(tmp[i].rstrip(')')))\n",
    "\n",
    "        #馬のデータを取得\n",
    "        papa_list = []\n",
    "        mama_list = []\n",
    "        mamapapa_list = []\n",
    "        for i in horse_url_list:\n",
    "            res = requests.get(i)\n",
    "            time.sleep(0.5)\n",
    "            soup = BeautifulSoup(res.content,features='html.parser')\n",
    "            tbody = soup.find('tbody')\n",
    "            if '父' in tbody.find('th',attrs={'class':\"Sire\"}).text:\n",
    "                papa_list.append(tbody.find('td',attrs={'class':'Sire'}).text.replace(u'\\n',u''))\n",
    "                mama_list.append(tbody.find('td',attrs={'class':'Dam'}).text.replace(u'\\n',u'').split('母')[0])\n",
    "                mamapapa_list.append(tbody.find('td',attrs={'class':'Dam'}).text.replace(u'\\n',u'').split('母')[1].split(':')[1])\n",
    "            else:\n",
    "                papa_list.append('-')\n",
    "                mama_list.append('-')\n",
    "                mamapapa_list.append('-')\n",
    "        \n",
    "        df = pd.DataFrame({'年度':year,'馬場':baba,'着順':rank,'馬番':num,'枠番':waku,'馬名':horse_name,'性':sex,'齢':age,'斤量':hakuryo,'騎手':jockey,'通過':tuka,'単勝':odds,'人気':pop,'馬体重':weight,'馬体増減':weight_2,'父':papa_list,'母':mama_list,'母父':mamapapa_list})\n",
    "\n",
    "        \n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13972210",
   "metadata": {},
   "outputs": [],
   "source": [
    "now_year = datetime.date.today().year\n",
    "df_divident_all = keiba.divident(race_url_list,now_year-10)\n",
    "#1つ目出力するよう、二つ目が割合の計算用\n",
    "df_ten = keiba.result(race_url_list,10)\n",
    "df_all = keiba.result(race_url_list,now_year-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3178cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sashi\\AppData\\Local\\Temp\\ipykernel_20312\\1727945702.py:8: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  new_df_vic_ten = df_ten[bool_list_3].reset_index()\n",
      "C:\\Users\\sashi\\AppData\\Local\\Temp\\ipykernel_20312\\1727945702.py:11: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_vic_ten = df_ten[bool_list_3].reset_index().drop(drop_col_2,axis=1)\n",
      "C:\\Users\\sashi\\AppData\\Local\\Temp\\ipykernel_20312\\1727945702.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  new_df_in_ten = df_ten[bool_list_1].reset_index()\n",
      "C:\\Users\\sashi\\AppData\\Local\\Temp\\ipykernel_20312\\1727945702.py:21: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_in_3_ten = df_ten[bool_list_1].reset_index().drop(drop_col_2,axis=1)\n",
      "C:\\Users\\sashi\\AppData\\Local\\Temp\\ipykernel_20312\\1727945702.py:28: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  new_df_ana_ten = df_ten[bool_list_2].reset_index()\n",
      "C:\\Users\\sashi\\AppData\\Local\\Temp\\ipykernel_20312\\1727945702.py:31: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_ana_ten = df_ten[bool_list_2].reset_index().drop(drop_col_2,axis=1)\n"
     ]
    }
   ],
   "source": [
    "#1986年まで\n",
    "#一着\n",
    "drop_col = ['馬場','index','年度','騎手','父','母','母父','単勝','馬名']\n",
    "drop_col_2 = ['馬場','index','年度','単勝','馬名']\n",
    "bool_list_3 = df_all['着順'] == 1\n",
    "#エクセルに出力する\n",
    "new_df_vic = df_all[bool_list_3].reset_index()\n",
    "new_df_vic_ten = df_ten[bool_list_3].reset_index()\n",
    "#計算に使う\n",
    "df_vic = df_all[bool_list_3].reset_index().drop(drop_col,axis=1)\n",
    "df_vic_ten = df_ten[bool_list_3].reset_index().drop(drop_col_2,axis=1)\n",
    "\n",
    "\n",
    "#三着以内\n",
    "bool_list_1 = df_all['着順'] <= 3\n",
    "#エクセルに出力する\n",
    "new_df_in = df_all[bool_list_1].reset_index()\n",
    "new_df_in_ten = df_ten[bool_list_1].reset_index()\n",
    "#計算に使う\n",
    "df_in_3 = df_all[bool_list_1].reset_index().drop(drop_col,axis=1)\n",
    "df_in_3_ten = df_ten[bool_list_1].reset_index().drop(drop_col_2,axis=1)\n",
    "\n",
    "\n",
    "#穴馬\n",
    "bool_list_2 = (df_all['人気'] >= 6) & (df_all['着順'] <= 3)\n",
    "#エクセルに出力する\n",
    "new_df_ana = df_all[bool_list_2].reset_index()\n",
    "new_df_ana_ten = df_ten[bool_list_2].reset_index()\n",
    "#計算に使う\n",
    "df_ana = df_all[bool_list_2].reset_index().drop(drop_col,axis=1)\n",
    "df_ana_ten = df_ten[bool_list_2].reset_index().drop(drop_col_2,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6879e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuka_split(df_list):\n",
    "    new_df_list = []\n",
    "    for df in df_list:\n",
    "        one = []\n",
    "        two = []\n",
    "        three = []\n",
    "        four = []\n",
    "        for i in df['通過']:\n",
    "            tmp = i.split('-')\n",
    "            if len(tmp) >= 3:\n",
    "                three.append(int(tmp[2]))\n",
    "                if len(tmp) == 4:\n",
    "                    four.append(int(tmp[3]))\n",
    "            one.append(int(tmp[0]))\n",
    "            two.append(int(tmp[1]))\n",
    "            if len(one) > len(three):\n",
    "                three.append('-')\n",
    "            elif len(one) > len(four):\n",
    "                four.append('-')\n",
    "        corner_rank = {'1コーナー':one,'2コーナー':two,'3コーナー':three,'4コーナー':four}\n",
    "        if corner_rank['3コーナー'] == []:\n",
    "            del corner_rank['4コーナー'], corner_rank['3コーナー']\n",
    "        elif corner_rank['3コーナー'] != [] and corner_rank['4コーナー'] == []:\n",
    "            del corner_rank['4コーナー']\n",
    "        corner_df = pd.DataFrame(corner_rank)\n",
    "        tmp = df.drop('通過',axis=1)\n",
    "        new_df = pd.concat([tmp,corner_df],axis = 1)\n",
    "        new_df_list.append(new_df)\n",
    "    return new_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6444bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算用のデータ形成,エクセル出力に使用\n",
    "df_list_all = [df_vic,df_in_3,df_ana]\n",
    "df_list_ten = [df_vic_ten,df_in_3_ten,df_ana_ten]\n",
    "\n",
    "\n",
    "#計算に使用\n",
    "new_df_list_all = tuka_split(df_list_all)\n",
    "new_df_list_ten = tuka_split(df_list_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e01fbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_weight(df_list):\n",
    "    n_df_list = []\n",
    "    for df in df_list:\n",
    "        new_weight = []\n",
    "        for count,content in enumerate(df['馬体重']):\n",
    "            new_weight.append(content-int(str(content)[-1]))\n",
    "        df['馬体重'] = new_weight\n",
    "        n_df_list.append(pd.DataFrame(df))\n",
    "    return df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4be338bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rate_calでつかう！！  0に勝ち馬のデータ、１に三着以内のデータ、２に穴馬のデータ\n",
    "n_df_all = round_weight(new_df_list_all)\n",
    "n_df_list_ten = round_weight(new_df_list_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "617bbaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###indexをintに変換するところから\n",
    "def rate_calcurater(df_list):\n",
    "    rate_df_list = []\n",
    "    for df in df_list:\n",
    "        for column in df:\n",
    "            if column != '着順':\n",
    "                index_list = []\n",
    "                rate_list = []\n",
    "                for index ,rate in df[column].value_counts(normalize=True).iteritems():\n",
    "                    if type(index) == float:\n",
    "                        index_list.append(int(index))\n",
    "                    else:\n",
    "                        index_list.append(index)\n",
    "                    rate_list.append(rate)\n",
    "                if column == '馬番':\n",
    "                    rate_df = pd.DataFrame({column:index_list,'':rate_list})\n",
    "                else:\n",
    "                    rate_df = pd.concat([rate_df,pd.DataFrame({column:index_list,'':rate_list})],axis=1).fillna('')\n",
    "        rate_df_list.append(rate_df)\n",
    "    return rate_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "19544a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_df_list_ten = rate_calcurater(n_df_list_ten)\n",
    "rate_df_list_all = rate_calcurater(n_df_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b025043",
   "metadata": {},
   "source": [
    "#過去十年と過去十年以上を別々のエクセルファイルとして出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22a2939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output_ten = []\n",
    "df_output_all = []\n",
    "for i in range(3):\n",
    "    df_output_ten.append(pd.concat([df_list_ten[i],rate_df_list_ten[i]],axis=1).fillna(''))\n",
    "    df_output_all.append(pd.concat([df_list_all[i],rate_df_list_all[i]],axis=1).fillna(''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9918ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [f'C:/Users/sashi/OneDrive/デスクトップ/競馬データ/{race_name}/配当.xlsx']\n",
    "for i in ['過去十年','全データ']:\n",
    "    file_paths.append(f'C:/Users/sashi/OneDrive/デスクトップ/競馬データ/{race_name}/{i}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a9d05",
   "metadata": {},
   "source": [
    "次回エクセル出力から"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34c417ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(file_paths):\n",
    "    if i == 0:\n",
    "        with pd.ExcelWriter(j) as writer:\n",
    "            df_divident_all.to_excel(writer,sheet_name='配当',encoding='shift_jis',index=False)\n",
    "    if i == 1:\n",
    "        with pd.ExcelWriter(j) as writer:\n",
    "            df_ten.to_excel(writer,sheet_name='レース結果',encoding='shift_jis',index=False)\n",
    "            df_output_ten[0].to_excel(writer,sheet_name='勝馬データ',encoding='shift_jis',index=False)\n",
    "            df_output_ten[1].to_excel(writer,sheet_name='３着以内データ',encoding='shift_jis',index=False)\n",
    "            df_output_ten[2].to_excel(writer,sheet_name='穴馬データ',encoding='shift_jis',index=False)\n",
    "    if i == 2 and len(df_all) != len(df_ten):\n",
    "        with pd.ExcelWriter(j) as writer:\n",
    "            df_all.to_excel(writer,sheet_name='レース結果',encoding='shift_jis',index=False)\n",
    "            df_output_all[0].to_excel(writer,sheet_name='勝馬データ',encoding='shift_jis',index=False)\n",
    "            df_output_all[1].to_excel(writer,sheet_name='３着以内データ',encoding='shift_jis',index=False)\n",
    "            df_output_all[2].to_excel(writer,sheet_name='穴馬データ',encoding='shift_jis',index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac6d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
